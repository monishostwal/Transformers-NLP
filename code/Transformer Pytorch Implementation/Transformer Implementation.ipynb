{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba02ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as f\n",
    "import torch\n",
    "from math import sqrt\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990cdb9f",
   "metadata": {},
   "source": [
    "# Self Attention Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799ac289",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[\n",
    "    [1,0,1,0],\n",
    "    [0,2,2,2],\n",
    "    [1,1,1,1]\n",
    "]],dtype=torch.float32)\n",
    "\n",
    "# query_w=torch.tensor([\n",
    "#     [0,0,1],\n",
    "#     [1,1,0],\n",
    "#     [0,1,0],\n",
    "#     [1,1,0]\n",
    "# ],dtype=torch.float32)\n",
    "\n",
    "# key_w=torch.tensor([\n",
    "#     [1,0,1],\n",
    "#     [1,0,0],\n",
    "#     [0,1,0],\n",
    "#     [1,0,1]\n",
    "# ],dtype=torch.float32)\n",
    "\n",
    "# value_w=torch.tensor([\n",
    "#     [1,0,1],\n",
    "#     [1,1,0],\n",
    "#     [0,1,1],\n",
    "#     [0,0,1]\n",
    "# ],dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2249385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(query,key,value):\n",
    "    dim_k=query.size(-1)\n",
    "    scores=torch.bmm(query,key.transpose(1,2))\n",
    "    weights=f.softmax(scores,dim=-1)\n",
    "    return torch.bmm(weights,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa96b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self,embed_dim,head_dim):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.head_dim = head_dim\n",
    "        self.to_query = nn.Linear(embed_dim, head_dim)\n",
    "#         self.to_query.weight = nn.Parameter(query_w.t())\n",
    "        self.to_key = nn.Linear(embed_dim, head_dim)\n",
    "#         self.to_key.weight = nn.Parameter(key_w.t())\n",
    "        self.to_value = nn.Linear(embed_dim, head_dim)\n",
    "#         self.to_value.weight = nn.Parameter(value_w.t())\n",
    "    def forward(self,inputs):\n",
    "#         print(self.q(inputs))\n",
    "        attention_output=scaled_dot_product(self.to_query(inputs),self.to_key(inputs),self.to_value(inputs))\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b18218",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention=AttentionHead(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "118b1f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4145,  0.2643, -0.8602],\n",
       "         [-0.4193,  0.2986, -0.8482],\n",
       "         [-0.4222,  0.2882, -0.8487]]], grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4670adfe",
   "metadata": {},
   "source": [
    "# Multi Headed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5f29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,embed_dim,num_heads):\n",
    "        super().__init__()\n",
    "        self.emded_dim=embed_dim\n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim=embed_dim//num_heads\n",
    "        self.heads=nn.ModuleList(AttentionHead(embed_dim,self.head_dim) for _ in range(num_heads))\n",
    "        self.output_layer=nn.Linear(embed_dim,embed_dim)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        x=torch.cat([calc_head(inputs) for calc_head in self.heads],dim=-1)\n",
    "        x=self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2028644",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head=MultiHeadAttention(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2afdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4922,  0.2438, -0.3506, -0.6668],\n",
       "         [-0.4585,  0.2299, -0.3184, -0.6346],\n",
       "         [-0.4613,  0.2292, -0.3187, -0.6343]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e2906",
   "metadata": {},
   "source": [
    "# Trying Multi head attention on BERT Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfc7b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_emb=nn.Embedding(30522,768) #vocab_size of bert,embedding dimension of bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac75c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd9fc3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "415890b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer(\"time flies like an arrow\",return_tensors='pt',add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03611f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 2051, 10029,  2066,  2019,  8612]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e084c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs in sparse matrix we want dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20c48d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_embeds=token_emb(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db7da523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b09ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head=MultiHeadAttention(768,12) # 768 embedding size and 12 heads in bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b0ddb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=multi_head(inputs_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b752c0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd921d",
   "metadata": {},
   "source": [
    "# FeedForward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d0827a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,embed_size,ff_size,dropout_prob):\n",
    "        super().__init__()\n",
    "        self.linear_1=nn.Linear(embed_size,ff_size)\n",
    "        self.linear_2=nn.Linear(ff_size,embed_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout=nn.Dropout(dropout_prob)\n",
    "    def forward(self,inputs):\n",
    "        x=self.linear_1(inputs)\n",
    "        x=self.relu(x)\n",
    "        x=self.linear_2(x)\n",
    "        x=self.dropout(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f32d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_layer=FeedForward(768,200,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae96aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_outputs=ff_layer(inputs_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a0ff3",
   "metadata": {},
   "source": [
    "# Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "397872f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,embed_dim,num_heads,ff_size):\n",
    "        super().__init__()\n",
    "        self.multiheadAttention=MultiHeadAttention(embed_dim,num_heads)\n",
    "        self.feedForward=FeedForward(embed_dim,ff_size,dropout_prob=0.2)\n",
    "        self.norm_layer1=nn.LayerNorm(embed_dim)\n",
    "        self.norm_layer2=nn.LayerNorm(embed_dim)\n",
    "    def forward(self,inputs):\n",
    "        attention_output=self.multiheadAttention(inputs)\n",
    "        x=attention_output+inputs\n",
    "        x=self.norm_layer1(x)\n",
    "        feed_output=self.feedForward(x)\n",
    "        x=feed_output+x\n",
    "        x=self.norm_layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18e0b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer=EncoderLayer(768,12,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80b91129",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=encoder_layer(inputs_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2945b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf0ddcf",
   "metadata": {},
   "source": [
    "# Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ebdda1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self,embed_size,vocab_size,max_position_embedding):\n",
    "        super().__init__()\n",
    "        self.token_embeddings=nn.Embedding(vocab_size,embed_size)\n",
    "        self.position_embedding=nn.Embedding(max_position_embedding,embed_size)\n",
    "        self.layer_norm=nn.LayerNorm(embed_size)\n",
    "        self.dropout=nn.Dropout()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        seq_length=inputs.size(1)\n",
    "        positions_id=[]\n",
    "        for i in range(len(inputs)):\n",
    "            single_position_lst=[]\n",
    "            for j in range(seq_length):\n",
    "                single_position_lst.append(j)\n",
    "            positions_id.append(single_position_lst)\n",
    "        positions_id=torch.LongTensor(positions_id)\n",
    "        token_embeddings=self.token_embeddings(inputs)\n",
    "        position_embedding=self.position_embedding(positions_id)\n",
    "        embeddings=token_embeddings+position_embedding\n",
    "        embeddings=self.layer_norm(embeddings)\n",
    "        embeddings=self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fd14e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=Embeddings(768,30522,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dbb827d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(inputs.input_ids).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5e65e",
   "metadata": {},
   "source": [
    "# Complete Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "277606ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self,embed_size,vocab_size,max_position_embedding,num_heads,ff_size,num_of_encoder_layers):\n",
    "        super().__init__()\n",
    "        self.embeddings=Embeddings(embed_size,vocab_size,max_position_embedding)\n",
    "        self.layers=nn.ModuleList([EncoderLayer(embed_size,num_heads,ff_size) for _ in range(num_of_encoder_layers)])\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        x=self.embeddings(inputs)\n",
    "        for layer in self.layers:\n",
    "            x=layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1930d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=TransformerEncoder(768,50322,512,12,100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ec8bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output=encoder(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d0c6a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0795,  0.1168,  0.0550,  ...,  1.1022, -0.9078,  2.1494],\n",
       "         [ 1.2178,  0.0405, -1.2665,  ..., -1.4237, -0.5697,  0.2349],\n",
       "         [ 2.0484,  0.1901,  1.0917,  ..., -0.4768, -0.6110,  0.7941],\n",
       "         [ 0.1756,  0.2771, -1.6968,  ..., -0.5076, -1.0719,  0.7918],\n",
       "         [ 0.2331,  0.3498, -1.3248,  ..., -0.8824, -2.1113, -0.5023]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53a2078",
   "metadata": {},
   "source": [
    "# Adding Classification Head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f318ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerForClassification(nn.Module):\n",
    "    def __init__(self,embed_size,vocab_size,max_position_embedding,num_heads,ff_size,num_of_encoder_layers,num_labels):\n",
    "        super().__init__()\n",
    "        self.encoder=TransformerEncoder(embed_size,vocab_size,max_position_embedding,num_heads,ff_size,num_of_encoder_layers)\n",
    "        self.dropout=nn.Dropout()\n",
    "        self.classifier=nn.Linear(embed_size,num_labels)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x=self.encoder(inputs)[:,0,:] # classify based on CLS token\n",
    "        x=self.dropout(x)\n",
    "        result=self.classifier(x)\n",
    "        result=f.softmax(result,dim=-1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "204ae85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=TransformerForClassification(768,50322,512,12,100,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b53bc097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs=tokenizer(\"time flies like an arrow\",return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "632f3309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4330, 0.3706, 0.1964]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfe746",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "723092d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder will work same as encoder except mask self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3535153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
